# Reference Library: Quality-Annotated Sources

## Purpose

This document provides a curated reference library for the AI-Augmented SDLC Framework academic paper. Each reference includes quality tier classification, methodological notes, known critiques, and appropriate citation guidance.

---

## Quality Tier Definitions

| Tier | Description | Citation Guidance |
|------|-------------|-------------------|
| **T1** | Peer-reviewed academic research in established journals | Can cite findings as evidence with confidence |
| **T2** | Formal international standards | Authoritative for definitions, processes, terminology |
| **T3** | Credible grey literature (think tanks, validated surveys) | Use with explicit methodology acknowledgment |
| **T4** | Industry/commercial sources | Context only; acknowledge commercial interest |
| **T5** | Contested sources | Use only with explicit methodological caveats |

---

## Tier 1: Peer-Reviewed Academic Research

### Foundational Works

#### Naur, P. (1985)
- **Title**: Programming as Theory Building
- **Source**: *Microprocessing and Microprogramming*, 15(5), 253-261
- **Type**: Philosophical/theoretical paper
- **Methodology**: Conceptual argument with illustrative cases from author's experience
- **Key findings**: Software development is fundamentally theory-building; the "program" exists in developers' minds, not in code; programs "die" when theory-holders leave
- **Limitations**: Cases are illustrative, not systematic empirical evidence; 40 years old
- **Citation guidance**: Cite as foundational theoretical work; note philosophical rather than empirical nature; acknowledge subsequent empirical validation by others
- **Citations**: 270+ (Google Scholar)

#### Polanyi, M. (1966)
- **Title**: The Tacit Dimension
- **Source**: University of Chicago Press
- **Type**: Philosophical work
- **Key concept**: "We can know more than we can tell" - tacit knowledge cannot be fully articulated
- **Citation guidance**: Foundational for tacit knowledge concept; philosophical, not empirical
- **Citations**: 10,000+ across all fields

#### Nonaka, I. & Takeuchi, H. (1995)
- **Title**: The Knowledge-Creating Company
- **Source**: Oxford University Press
- **Type**: Management theory
- **Key concept**: SECI model (Socialization, Externalization, Combination, Internalization)
- **Known critiques**: SECI model influential but not rigorously empirically validated; Gourlay (2006) and others question theoretical foundations
- **Citation guidance**: Cite as influential framework; note it is influential on practice but contested theoretically; do not present SECI as validated theory
- **Citations**: Thousands; highly influential in KM literature

---

### Empirical Research (Pre-2010)

#### Curtis, B., Krasner, H., & Iscoe, N. (1988)
- **Title**: A field study of the software design process for large systems
- **Source**: *Communications of the ACM*, 31(11), 1268-1287
- **Type**: Field study
- **Methodology**: 17 large projects, interviews with developers and managers
- **Key findings**: "Thin spread of application domain knowledge" as critical problem; knowledge acquisition central to development
- **Limitations**: Pre-internet era projects; may not generalise to modern contexts
- **Citation guidance**: Foundational empirical work; cite specific findings with confidence
- **Citations**: 2,339

#### Boehm, B. (1981)
- **Title**: Software Engineering Economics
- **Source**: Prentice-Hall
- **Type**: Empirical analysis with cost models
- **Key findings**: Cost of change curve (1x requirements â†’ 50-200x production)
- **Validation**: Extensively replicated; challenged in some agile contexts
- **Citation guidance**: Cite as foundational; note has been challenged in iterative/agile contexts but core insight about escalating costs remains valid
- **Citations**: Foundational; thousands of citations

#### Faraj, S. & Sproull, L. (2000)
- **Title**: Coordinating expertise in software development teams
- **Source**: *Management Science*, 46(12), 1554-1568
- **Type**: Quantitative study
- **Methodology**: Survey of software development teams
- **Key findings**: Expertise coordination (knowing who knows what) predicts team performance
- **Citation guidance**: High-quality quantitative study; cite findings with confidence
- **Citations**: 1,718

#### DybÃ¥, T. & DingsÃ¸yr, T. (2008)
- **Title**: Empirical studies of agile software development: A systematic review
- **Source**: *Information and Software Technology*, 50(9-10), 833-859
- **Type**: Systematic literature review
- **Methodology**: GRADE methodology; 1,996 studies reviewed, 36 met quality criteria
- **Key findings**: Evidence for agile rated "very low" quality; 73% of studies examined beginner teams; most studies lack control groups
- **Citation guidance**: Definitive review of agile evidence up to 2008; cite methodology findings with confidence
- **Citations**: Highly cited systematic review

#### BjÃ¸rnson, F.O. & DingsÃ¸yr, T. (2008)
- **Title**: Knowledge management in software engineering: A systematic review
- **Source**: *Information and Software Technology*, 50(11), 1055-1068
- **Type**: Systematic literature review
- **Methodology**: 762 articles analysed; 68 industry studies
- **Key findings**: Strong focus on explicit knowledge; need to consider tacit knowledge
- **Citation guidance**: Authoritative for state of KM research in SE; cite with confidence
- **Citations**: Hundreds

---

### Empirical Research (2010-2020)

#### Forsgren, N., Humble, J., & Kim, G. (2018)
- **Title**: Accelerate: The Science of Lean Software and DevOps
- **Source**: IT Revolution Press
- **Type**: Research synthesis based on State of DevOps surveys
- **Methodology**: Large-scale surveys; structural equation modelling; validated constructs
- **Key findings**: Four key metrics (DORA); elite performers 208x more frequent deployment; statistical relationships between practices and outcomes
- **Limitations**: Survey-based; self-reported; possible selection bias in respondents
- **Citation guidance**: Cite as most rigorous large-scale study of DevOps practices; acknowledge survey methodology
- **Citations**: Foundational for DORA metrics

#### Khoza, L. & Marnewick, C. (2020)
- **Title**: Waterfall and Agile information system project success rates - A South African perspective
- **Source**: *South African Computer Journal*, 32(1), 43-73
- **DOI**: 10.18489/sacj.v32i1.683
- **Type**: Quantitative survey
- **Methodology**: 617 projects; Bannerman framework (5 levels of success)
- **Key findings**: Agile 60% more effective at process level; no business success distinction; waterfall higher on project management success
- **Limitations**: South African context; may not generalise globally
- **Citation guidance**: Valuable for nuanced success measurement; cite specific findings with geographic caveat

---

### Empirical Research (2020-Present)

#### Verwijs, C. & Russo, D. (2023)
- **Title**: A theory of Scrum Team Effectiveness
- **Source**: *ACM Transactions on Software Engineering and Methodology*
- **Type**: Large-scale empirical study
- **Methodology**: ~5,000 developers, ~2,000 Scrum teams; validated instrument
- **Key findings**: Team factors (autonomy, responsiveness, management support) matter more than methodology; framework choice less important than enablers
- **Citation guidance**: Strongest recent empirical work on team effectiveness; cite findings with high confidence

#### Hicks, C. et al. (2024)
- **Title**: Developer Thriving: Four Sociocognitive Factors
- **Source**: Peer-reviewed research
- **Type**: Instrument development and validation
- **Methodology**: Multi-study validation; LABS model (Learning, Agency, Belonging, Self-efficacy)
- **Key findings**: Psychological factors foundation for sustainable productivity
- **Citation guidance**: Validated instrument; cite with confidence

#### NapoleÃ£o, B.M. et al. (2019)
- **Title**: Knowledge Management Strategies and Processes in Agile Software Development
- **Source**: *International Journal of Software Engineering and Knowledge Engineering*, 29(3), 345-380
- **DOI**: 10.1142/S0218194019500153
- **Type**: Systematic literature review
- **Methodology**: 32 primary studies analysed
- **Key findings**: 81% of agile KM practices implement personalisation (tacit); only 19% codification (explicit)
- **Citation guidance**: Rigorous systematic review; cite 81%/19% finding with confidence

#### Tobisch, F. & Matthes, F. (2025)
- **Title**: Knowledge Sharing and Coordination in Large-Scale Agile Software Development
- **Source**: *XP 2025*, Lecture Notes in Business Information Processing, vol. 545, 81-99
- **DOI**: 10.1007/978-3-031-94544-1_6
- **Type**: Mixed methods (systematic review + interviews)
- **Methodology**: 69 empirical studies; 9 expert interviews
- **Key findings**: 26 barriers to knowledge sharing; documentation as key enabler
- **Citation guidance**: Recent, rigorous study; cite with confidence

---

## Tier 2: Formal International Standards

### Software/Systems Lifecycle

| Standard | Title | Use for |
|----------|-------|---------|
| ISO/IEC/IEEE 12207:2017 | Software life cycle processes | Process definitions; 30 universal processes |
| ISO/IEC/IEEE 15288:2015 | System life cycle processes | Systems engineering alignment |
| ISO/IEC/IEEE 15289:2019 | Information items | Document types; 73+ information items |
| ISO/IEC/IEEE 29148:2018 | Requirements engineering | Requirements process guidance |
| ISO/IEC/IEEE 24765:2017 | Vocabulary | Terminology definitions |

### Quality and Defects

| Standard | Title | Use for |
|----------|-------|---------|
| IEEE 1044-2009 | Classification for Software Anomalies | Defect classification |
| ISO/IEC 25010:2011 | SQuaRE | Quality characteristics |

### Knowledge Base

| Standard | Title | Use for |
|----------|-------|---------|
| SWEBOK V4.0 (Oct 2024) | Guide to Software Engineering Body of Knowledge | Knowledge area taxonomy |
| IEEE 2675-2021 | DevOps | DevOps process mapping |

**Citation guidance**: Standards are authoritative for definitions and processes. Cite specific clauses where possible.

---

## Tier 3: Credible Grey Literature

### Research Organisation Reports

#### DORA / State of DevOps Reports
- **Publisher**: DORA (Google Cloud)
- **Methodology**: Large-scale annual surveys; validated constructs; structural equation modelling
- **Strengths**: Large sample sizes; consistent methodology over years; statistical rigour
- **Limitations**: Self-selected respondents; self-reported data; potential survivorship bias
- **Citation guidance**: Cite with methodology acknowledgment; "According to DORA's large-scale survey research..."

#### RAND Corporation Studies
- **Type**: Think tank research
- **Strengths**: Methodologically rigorous; expert interviews; transparent methodology
- **Limitations**: Not peer-reviewed; may reflect funder interests
- **Citation guidance**: Cite with source type acknowledgment; "RAND Corporation research suggests..."

---

## Tier 4: Industry/Commercial Sources (Context Only)

These sources should NOT be used as primary evidence for academic claims. They may be useful for context about industry adoption or practitioner perspectives.

### Analyst Firms (Promotional Bias)

| Source | Bias Concern | Use for |
|--------|--------------|---------|
| Gartner | Commercial predictions | Industry adoption context only |
| Forrester | Commercial research | Industry trends context only |
| McKinsey | Consulting firm | Business context only |
| BCG | Consulting firm | Business context only |

### Industry Surveys (Selection/Sponsorship Bias)

| Source | Bias Concern | Use for |
|--------|--------------|---------|
| State of Agile Report | Sponsored by agile vendors | Adoption statistics with caveat |
| Stack Overflow Survey | Self-selected developers | Demographics context |
| GitHub Octoverse | GitHub users only | Usage patterns context |

### Vendor Research (Commercial Interest)

| Source | Bias Concern | Citation Guidance |
|--------|--------------|-------------------|
| Engprax / Impact Engineering | Commercial research promoting specific methodology | DO NOT USE as evidence |
| Scrum Inc. | Commercial training provider | DO NOT USE as evidence |
| GitLab surveys | Vendor promoting own tools | Context only with caveat |

---

## Tier 5: Contested Sources

### Standish Group CHAOS Reports

**What it is**: Proprietary research tracking IT project success rates since 1994

**Why it's contested**:
1. Proprietary methodology not published for peer review
2. Definition of "success" changed over time
3. Sample selection methodology unclear
4. Has been criticised by:
   - Glass, R.L. (2006). The Standish Report: Does It Really Describe a Software Crisis? *Communications of the ACM*, 49(8), 15-16
   - Eveleens, J.L. & Verhoef, C. (2010). The Rise and Fall of the Chaos Report Figures. *IEEE Software*, 27(1), 30-36

**Why it's still cited**: Widely influential; longitudinal data; industry recognition

**Citation guidance**: May cite for historical context or trend discussion ONLY with explicit methodological caveat. Example: "The Standish Group's CHAOS reports, despite methodological criticisms (Glass, 2006; Eveleens & Verhoef, 2010), have tracked industry success rates since 1994, reporting improvement from 16% (1994) to 31% (2020)."

---

## References NOT to Use

The following sources appeared in earlier project documents and should NOT be used in the academic paper without significant caveats or at all:

| Source | Problem | Action |
|--------|---------|--------|
| Engprax "97% more likely to succeed" | Commercial research, not peer-reviewed | DO NOT USE |
| Various unsourced statistics (e.g., "70-80% of knowledge is tacit") | Cannot be verified | Verify or remove |
| Practitioner heuristics presented as thresholds | Not empirically validated | Reframe as guidance, not evidence |
| Causal claims from observational data | Correlation â‰  causation | Reframe appropriately |

---

## Template for Adding New References

When adding references to this library, include:

```markdown
#### [Author(s)] ([Year])
- **Title**: 
- **Source**: [Journal/Conference/Publisher]
- **Type**: [Empirical study / Systematic review / Theoretical / Standard / Grey literature]
- **Methodology**: [Brief description]
- **Key findings**: 
- **Limitations**: 
- **Known critiques**: 
- **Citation guidance**: 
- **Quality tier**: T[1-5]
```

---

## Usage Guidelines

1. **For claims requiring evidence**: Use only T1 sources
2. **For definitions and processes**: Use T2 standards
3. **For industry context**: T3-T4 with explicit acknowledgment
4. **For contested claims**: T5 with full methodological caveat
5. **Never present T4-T5 as equivalent to T1 evidence**

---

*Document version: 1.0*
*Purpose: Provide quality-annotated reference library for academic paper*
*Maintenance: Add new references using template; update annotations as new critiques emerge*
